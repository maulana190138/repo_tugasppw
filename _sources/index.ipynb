{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75fcbef8",
   "metadata": {},
   "source": [
    "<h2>Crawling data</h2>\n",
    "\n",
    "<p>code dibawah digunakan untuk mengcrawling data dari sebuah website yang nantinya akan diolah dengan stemming, tf-idf dan lian-lain</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b56e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        start_urls = [\n",
    "            'https://pta.trunojoyo.ac.id/welcome/index/10',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/index/11',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/index/12',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/index/13',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/index/14',\n",
    "        ]\n",
    "\n",
    "        for url in start_urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        for item in response.css('#content_journal > ul > li'):\n",
    "            yield {\n",
    "                'Link': item.css(f'div:nth-child(3) > div:nth-child(5) > a::attr(href)').get(),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad925f",
   "metadata": {},
   "source": [
    "<p>code diatas digunakan untuk mengambil link setiap dari website yang nantinya akan diproses lebih lebih lanjut menggunakan kode dibawah, data yang dihasilkan nantinya akan dikonversi ke dalam file csv<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27eb472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quote\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        data_csv = pd.read_csv('hasil_crawl.csv').values\n",
    "        start_urls = [ link[0] for link in data_csv ]\n",
    "\n",
    "        for url in start_urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        yield {\n",
    "            'Judul': response.css('#content_journal > ul > li > div:nth-child(2) > a::text').get(),\n",
    "            'Abstraksi': response.css('#content_journal > ul > li > div:nth-child(4) > div:nth-child(2) > p::text').get(),\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67eed29",
   "metadata": {},
   "source": [
    "<h1>Topic Modeling menggunakan LDA dan LSA dengan Jupyter Notebook</h1>\n",
    "\n",
    "<p> <em>Latent Dirichlet Allocation</em> (LDA) adalah jenis pemodelan statistik untuk menemukan \"topik\" abstrak yang terjadi dalam kumpulan dokumen. Latent Dirichlet Allocation (LDA) adalah contoh model topik dan digunakan untuk mengklasifikasikan teks dalam dokumen ke topik tertentu. Itu membangun topik per model dokumen dan kata-kata per model topik, dimodelkan sebagai distribusi Dirichlet.</p>\n",
    "\n",
    "<p> <em>Latent Semantic Analysis</em> (LSA) adalah salah satu teknik dasar dalam pemodelan topik. Ide intinya adalah mengambil matriks dari apa yang kita miliki — dokumen dan istilah — dan menguraikannya menjadi matriks topik-dokumen yang terpisah dan matriks topik-istilah.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd2054f",
   "metadata": {},
   "source": [
    "<h3>Install Library</h3>\n",
    "\n",
    "<p>Dibawah ini dicantumkan beberapa library yang dibutuhkan untuk menlakukan processing menggunakan LSA dengan jupyter notebook, anda juga bisa melakukan instalasi ini dengan menggunakan CMD untuk pengguna Windows atau Terminal untuk pengguna Linux</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae87bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy\n",
    "pip install sklearn\n",
    "pip install pandas\n",
    "pip install matplotlib\n",
    "pip install seaborn\n",
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73926678",
   "metadata": {},
   "source": [
    "<h3>Import Library</h3>\n",
    "\n",
    "<p>Untuk library yang digunakan diantaranya ada numpy, pandas, matplotlib, seaborn, nltk, dan sklearn yang umum digunakan pada data processing</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "724deafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "#preprocessing\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "\n",
    "# for named entity recognition (NER)\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# vectorizers for creating the document-term-matrix (DTM)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "\n",
    "#stop-words\n",
    "stop_words=set(nltk.corpus.stopwords.words('indonesian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4af06dc",
   "metadata": {},
   "source": [
    "<h3>Instalasi Library Tambahan</h3>\n",
    "<p>Dibawah ini ada library tambahan yang harus diinstall untuk memroses kata-kata</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da37ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('corpus')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282249e5",
   "metadata": {},
   "source": [
    "<h3>Import dokumen</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a558e6c1",
   "metadata": {},
   "source": [
    "<p>Import dokumen yang sudah dicrawling dengan crawler, bisa menggunakan referensi dari web ini atau bisa menggunakan referensi kode dari website lain</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d3fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'abstrak.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f2ff4",
   "metadata": {},
   "source": [
    "<h3>Display 10 data teratas pada dokumen</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b485343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>Abstrak</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SISTEM PENENTUAN STATUS GIZI PASIEN RAWAT INAP...</td>\n",
       "      <td>Di Indonesia masalah perkembangan gizi adalah ...</td>\n",
       "      <td>CAI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE \\...</td>\n",
       "      <td>Sistem  informasi  akademik  (SIAKAD) merupaka...</td>\n",
       "      <td>RPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RANCANG BANGUN APLIKASI INTRUSION PREVENTION S...</td>\n",
       "      <td>Dalam setiap perusahaan tentunya memiliki data...</td>\n",
       "      <td>RPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEMANFAATAN TOGAF ADM UNTUK PERANCANGAN SISTEM...</td>\n",
       "      <td>Penyusunan Sistem Informasi Dinas Perindustria...</td>\n",
       "      <td>CAI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APLIKASI DAN DESAIN MODEL DECISION AID PELANGG...</td>\n",
       "      <td>Toko Batik Tulis Madura merupakan salah satu t...</td>\n",
       "      <td>RPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gerak Pekerja Pada Game Real Time Strategy Men...</td>\n",
       "      <td>Gerak pekerja ada pada game yang memiliki genr...</td>\n",
       "      <td>CAI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RANCANG BANGUN SISTEM INFORMASI PEMETAAN TANAM...</td>\n",
       "      <td>Kabupaten Bangkalan memiliki lahan pertanian s...</td>\n",
       "      <td>RPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PERANCANGAN SISTEM INFORMASI PERENCANAAN PRODU...</td>\n",
       "      <td>Penelitian ini membahas tentang perancangan si...</td>\n",
       "      <td>RPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RANCANG BANGUN APLIKASI SEARCH ENGINE DAN SIST...</td>\n",
       "      <td>Plagiarisme adalah mencuri gagasan, kata-kata,...</td>\n",
       "      <td>RPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IMPLEMENTASI  METODE N-GRAM PADA PEMBUATAN GAM...</td>\n",
       "      <td>Teknologi mobile  game  berkembang  dengan  sa...</td>\n",
       "      <td>CAI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  SISTEM PENENTUAN STATUS GIZI PASIEN RAWAT INAP...   \n",
       "1  PERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE \\...   \n",
       "2  RANCANG BANGUN APLIKASI INTRUSION PREVENTION S...   \n",
       "3  PEMANFAATAN TOGAF ADM UNTUK PERANCANGAN SISTEM...   \n",
       "4  APLIKASI DAN DESAIN MODEL DECISION AID PELANGG...   \n",
       "5  Gerak Pekerja Pada Game Real Time Strategy Men...   \n",
       "6  RANCANG BANGUN SISTEM INFORMASI PEMETAAN TANAM...   \n",
       "7  PERANCANGAN SISTEM INFORMASI PERENCANAAN PRODU...   \n",
       "8  RANCANG BANGUN APLIKASI SEARCH ENGINE DAN SIST...   \n",
       "9  IMPLEMENTASI  METODE N-GRAM PADA PEMBUATAN GAM...   \n",
       "\n",
       "                                             Abstrak label  \n",
       "0  Di Indonesia masalah perkembangan gizi adalah ...   CAI  \n",
       "1  Sistem  informasi  akademik  (SIAKAD) merupaka...   RPL  \n",
       "2  Dalam setiap perusahaan tentunya memiliki data...   RPL  \n",
       "3  Penyusunan Sistem Informasi Dinas Perindustria...   CAI  \n",
       "4  Toko Batik Tulis Madura merupakan salah satu t...   RPL  \n",
       "5  Gerak pekerja ada pada game yang memiliki genr...   CAI  \n",
       "6  Kabupaten Bangkalan memiliki lahan pertanian s...   RPL  \n",
       "7  Penelitian ini membahas tentang perancangan si...   RPL  \n",
       "8  Plagiarisme adalah mencuri gagasan, kata-kata,...   RPL  \n",
       "9  Teknologi mobile  game  berkembang  dengan  sa...   CAI  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3dae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(headline):\n",
    "    le=WordNetLemmatizer()\n",
    "    word_tokens=word_tokenize(headline)\n",
    "    tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>3]\n",
    "    cleaned_text=\" \".join(tokens)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e093d8",
   "metadata": {},
   "source": [
    "<h3>Pembersihan dokumen</h3>\n",
    "\n",
    "<p>pembersihan dokumen diperlukan agar supaya dalam proses TF/IDF tidak ada simbol-simbol yang masuk dalam proses tersebut yang mengakibatkan dokumen menjadi kurang otentik</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12deb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time taking\n",
    "df['abstrak_cleaned']=df['Abstrak'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6d09f",
   "metadata": {},
   "source": [
    "<h3>Perbandingan data yang belum dan sudah dibershkan</3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15dd74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>Abstrak</th>\n",
       "      <th>label</th>\n",
       "      <th>abstrak_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SISTEM PENENTUAN STATUS GIZI PASIEN RAWAT INAP...</td>\n",
       "      <td>Di Indonesia masalah perkembangan gizi adalah ...</td>\n",
       "      <td>CAI</td>\n",
       "      <td>Indonesia perkembangan gizi perhatian Jika sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE \\...</td>\n",
       "      <td>Sistem  informasi  akademik  (SIAKAD) merupaka...</td>\n",
       "      <td>RPL</td>\n",
       "      <td>Sistem informasi akademik SIAKAD sistem inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RANCANG BANGUN APLIKASI INTRUSION PREVENTION S...</td>\n",
       "      <td>Dalam setiap perusahaan tentunya memiliki data...</td>\n",
       "      <td>RPL</td>\n",
       "      <td>Dalam perusahaan memiliki data berkaitan kegia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEMANFAATAN TOGAF ADM UNTUK PERANCANGAN SISTEM...</td>\n",
       "      <td>Penyusunan Sistem Informasi Dinas Perindustria...</td>\n",
       "      <td>CAI</td>\n",
       "      <td>Penyusunan Sistem Informasi Dinas Perindustria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APLIKASI DAN DESAIN MODEL DECISION AID PELANGG...</td>\n",
       "      <td>Toko Batik Tulis Madura merupakan salah satu t...</td>\n",
       "      <td>RPL</td>\n",
       "      <td>Toko Batik Tulis Madura salah toko beroperasi ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  SISTEM PENENTUAN STATUS GIZI PASIEN RAWAT INAP...   \n",
       "1  PERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE \\...   \n",
       "2  RANCANG BANGUN APLIKASI INTRUSION PREVENTION S...   \n",
       "3  PEMANFAATAN TOGAF ADM UNTUK PERANCANGAN SISTEM...   \n",
       "4  APLIKASI DAN DESAIN MODEL DECISION AID PELANGG...   \n",
       "\n",
       "                                             Abstrak label  \\\n",
       "0  Di Indonesia masalah perkembangan gizi adalah ...   CAI   \n",
       "1  Sistem  informasi  akademik  (SIAKAD) merupaka...   RPL   \n",
       "2  Dalam setiap perusahaan tentunya memiliki data...   RPL   \n",
       "3  Penyusunan Sistem Informasi Dinas Perindustria...   CAI   \n",
       "4  Toko Batik Tulis Madura merupakan salah satu t...   RPL   \n",
       "\n",
       "                                     abstrak_cleaned  \n",
       "0  Indonesia perkembangan gizi perhatian Jika sta...  \n",
       "1  Sistem informasi akademik SIAKAD sistem inform...  \n",
       "2  Dalam perusahaan memiliki data berkaitan kegia...  \n",
       "3  Penyusunan Sistem Informasi Dinas Perindustria...  \n",
       "4  Toko Batik Tulis Madura salah toko beroperasi ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801930c7",
   "metadata": {},
   "source": [
    "<p>Dorp kolom Abstrak</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9097d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Abstrak'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f24c66c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>label</th>\n",
       "      <th>abstrak_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SISTEM PENENTUAN STATUS GIZI PASIEN RAWAT INAP...</td>\n",
       "      <td>CAI</td>\n",
       "      <td>Indonesia perkembangan gizi perhatian Jika sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE \\...</td>\n",
       "      <td>RPL</td>\n",
       "      <td>Sistem informasi akademik SIAKAD sistem inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RANCANG BANGUN APLIKASI INTRUSION PREVENTION S...</td>\n",
       "      <td>RPL</td>\n",
       "      <td>Dalam perusahaan memiliki data berkaitan kegia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEMANFAATAN TOGAF ADM UNTUK PERANCANGAN SISTEM...</td>\n",
       "      <td>CAI</td>\n",
       "      <td>Penyusunan Sistem Informasi Dinas Perindustria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APLIKASI DAN DESAIN MODEL DECISION AID PELANGG...</td>\n",
       "      <td>RPL</td>\n",
       "      <td>Toko Batik Tulis Madura salah toko beroperasi ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul label  \\\n",
       "0  SISTEM PENENTUAN STATUS GIZI PASIEN RAWAT INAP...   CAI   \n",
       "1  PERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE \\...   RPL   \n",
       "2  RANCANG BANGUN APLIKASI INTRUSION PREVENTION S...   RPL   \n",
       "3  PEMANFAATAN TOGAF ADM UNTUK PERANCANGAN SISTEM...   CAI   \n",
       "4  APLIKASI DAN DESAIN MODEL DECISION AID PELANGG...   RPL   \n",
       "\n",
       "                                     abstrak_cleaned  \n",
       "0  Indonesia perkembangan gizi perhatian Jika sta...  \n",
       "1  Sistem informasi akademik SIAKAD sistem inform...  \n",
       "2  Dalam perusahaan memiliki data berkaitan kegia...  \n",
       "3  Penyusunan Sistem Informasi Dinas Perindustria...  \n",
       "4  Toko Batik Tulis Madura salah toko beroperasi ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ae645",
   "metadata": {},
   "source": [
    "<p>Data frame kolom abstrak_cleaned</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ffa6080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Indonesia perkembangan gizi perhatian Jika status gizinya mengontrol gizi dibutuhkan tubuh Dalam penelitian dirancang aplikasi sistem pendukung keputusan menentukan status gizi pasien solusi makanan pasien sesuai riwayat penyakit derita pasien Sistem dirancang berbasis memudahkan admin ahli gizi rumah sakit penentuan status gizi pasien Diharapkan aplikasi efisien efektifitas kinerja Metode penelitian Naïve Bayes Classifier Metode terbaru memprediksi probabilitas.Metode Naïve bayes Classifier prose penentuan perhitungan probabilitas status gizi Dimana dicari nilai probabilitas terbesar kesimpulan penentuan status gizi Metode diterapkan studi Sistem Penentuan Status Gizi Pasien hasil akurasi terbesar Kata Kunci Naïve Bayes Classifier Sistem Pendukung Keputusan Status Gizi'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['abstrak_cleaned'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5163d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect =TfidfVectorizer(stop_words=stop_words,max_features=1000) # to play with. min_df,max_df,max_features etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4886e1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vect_text=vect.fit_transform(df['abstrak_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed3e0ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 1000)\n",
      "      0    1    2    3        4    5    6    7    8    9   ...   43        44  \\\n",
      "0    0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
      "1    0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
      "2    0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.065267   \n",
      "3    0.0  0.0  0.0  0.0  0.06755  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
      "4    0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
      "..   ...  ...  ...  ...      ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
      "995  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
      "996  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
      "997  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
      "998  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
      "999  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
      "\n",
      "           45   46        47   48        49   50   51   52  \n",
      "0    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  \n",
      "1    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  \n",
      "2    0.056598  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  \n",
      "3    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  \n",
      "4    0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  \n",
      "..        ...  ...       ...  ...       ...  ...  ...  ...  \n",
      "995  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  \n",
      "996  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  \n",
      "997  0.000000  0.0  0.000000  0.0  0.214971  0.0  0.0  0.0  \n",
      "998  0.000000  0.0  0.065046  0.0  0.000000  0.0  0.0  0.0  \n",
      "999  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  \n",
      "\n",
      "[1000 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "print(vect_text.shape)\n",
    "vect_text = vect_text.transpose()\n",
    "df = pd.DataFrame(vect_text.toarray())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7dd6d3",
   "metadata": {},
   "source": [
    "<h2>Term Frequency</h2>\n",
    "\n",
    "<p>Data di atas adalah data yang sudah diproses menggunakan TF-IDF untuk menentukan Term Frequency tiap topik. TF-IDF (Term Frequency - Inverse Document Frequency) adalah algoritma praktis yang menggunakan frekuensi kata untuk menentukan seberapa relevan kata-kata itu dengan dokumen tertentu. Ini adalah pendekatan yang relatif sederhana namun intuitif untuk pembobotan kata, memungkinkannya bertindak sebagai titik awal yang bagus untuk berbagai tugas.</p>\n",
    "<h3>Rumus TF-IDF</h3>\n",
    "\n",
    "$$\n",
    "\\operatorname{tf}(t, d)=\\frac{f_{t, d}}{\\sum_{t^{\\prime} \\in d} f_{t^{\\prime}, d}}\n",
    "$$\n",
    "\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eabcf312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metode yale\n",
      "4.295836866004329\n",
      "2.9095425048844383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "idf=vect.idf_\n",
    "dd=dict(zip(vect.get_feature_names(), idf))\n",
    "l=sorted(dd, key=(dd).get)\n",
    "# print(l)\n",
    "print(l[0],l[-1])\n",
    "print(dd['gizi'])\n",
    "print(dd['indonesia'])  # police is most common and forecast is least common among the news headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c39f1",
   "metadata": {},
   "source": [
    "<h2>Proses LSA</h2>\n",
    "\n",
    "<p>LSA  adalah metode yang memungkinkan kita mengekstrak topik dari dokumen dengan mengubah teksnya menjadi matriks topik-kata dan topik-dokumen. Prosedur untuk LSA relatif mudah: Ubah korpus teks menjadi matriks istilah dokumen. Menerapkan dekomposisi nilai singular terpotong.</p>\n",
    "\n",
    "$A_{m n}=U_{m m} x S_{m n} x V_{n n}^{T}$\n",
    "\n",
    "<p>Matriks U = baris merepresentasikan vektor pada topic dokumen</p>\n",
    "<p>Matriks V = Garis ini merepresentasikan vektor istilah yang dinyatakan pada topik</p>\n",
    "<p>Matriks S = Matriks diagonal yang memiliki elemen-elemen diagonal yang digunakan sebagai nilai singular A</p>\n",
    "\n",
    "<p>tiap baris pada matriks U merupakan representasi vektor yang terdapat pada dokumen yang sesuai, untuk melakukannya dapat menggunakan library SKLearn yang bernama TruncatedSVD untuk menimplementasikan LSA</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb3b78a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6  \\\n",
      "0    0.022513  0.014103  0.001021 -0.032999 -0.008429  0.010007 -0.004351   \n",
      "1    0.066848  0.036675 -0.006424  0.120559  0.006876  0.011078  0.014678   \n",
      "2    0.050591  0.023327  0.003047  0.041339 -0.009654  0.040480 -0.007151   \n",
      "3    0.015598 -0.020772  0.011073 -0.004783  0.007014 -0.003704 -0.014951   \n",
      "4    0.028148 -0.034250  0.036041  0.010536 -0.029183 -0.007120 -0.039525   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "995  0.025739 -0.050619 -0.062993 -0.008465  0.020182  0.014993 -0.038840   \n",
      "996  0.017284  0.019783 -0.003151  0.015708  0.006698 -0.000563 -0.005028   \n",
      "997  0.019228 -0.016835  0.010406  0.005682 -0.066119 -0.066268 -0.012515   \n",
      "998  0.003348 -0.004964  0.003263 -0.002041 -0.003350  0.011977  0.007883   \n",
      "999  0.044566  0.024450 -0.004283  0.080373  0.004584  0.007386  0.009785   \n",
      "\n",
      "            7         8         9  \n",
      "0    0.002334  0.019817  0.003725  \n",
      "1    0.019981  0.025415  0.010957  \n",
      "2   -0.006759  0.019147  0.012555  \n",
      "3    0.004884 -0.006504 -0.015267  \n",
      "4    0.084961 -0.064561 -0.065436  \n",
      "..        ...       ...       ...  \n",
      "995 -0.018483  0.010536 -0.032480  \n",
      "996 -0.006269 -0.010462 -0.003741  \n",
      "997 -0.024937  0.003852 -0.000627  \n",
      "998 -0.009678 -0.007944 -0.007692  \n",
      "999  0.013320  0.016944  0.007305  \n",
      "\n",
      "[1000 rows x 10 columns]\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=10, random_state=42)\n",
    "\n",
    "lsa_top=lsa_model.fit_transform(vect_text)\n",
    "print(pd.DataFrame(lsa_top))\n",
    "print(lsa_top.shape)  # (no_of_doc*no_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1e34d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 :\n",
      "Topic  0  :  2.2512533847059077\n",
      "Topic  1  :  1.4103483378595856\n",
      "Topic  2  :  0.1021361522709356\n",
      "Topic  3  :  -3.29989132987768\n",
      "Topic  4  :  -0.8428659594988172\n",
      "Topic  5  :  1.0007158831415892\n",
      "Topic  6  :  -0.43505022159714185\n",
      "Topic  7  :  0.23342382167115988\n",
      "Topic  8  :  1.9816560404465673\n",
      "Topic  9  :  0.37254435688536247\n"
     ]
    }
   ],
   "source": [
    "l=lsa_top[0]\n",
    "print(\"Document 0 :\")\n",
    "for i,topic in enumerate(l):\n",
    "  print(\"Topic \",i,\" : \",topic*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "507a4e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 53)\n",
      "         0         1         2         3         4         5         6   \\\n",
      "0  0.068430  0.087569  0.048283  0.050515  0.069584  0.041484  0.070037   \n",
      "1 -0.034432 -0.076677 -0.035018 -0.047440 -0.041196 -0.028298 -0.076400   \n",
      "2  0.090693  0.089060  0.055761  0.039443  0.069585  0.049706  0.016740   \n",
      "3  0.009532 -0.003035  0.009132 -0.026681 -0.034690 -0.009576  0.002577   \n",
      "4 -0.008122  0.030229 -0.035918 -0.032988 -0.042260 -0.153400  0.013233   \n",
      "5  0.006432 -0.047401 -0.031839  0.057835 -0.023972  0.204769  0.079421   \n",
      "6 -0.067881  0.218470  0.141479  0.072707  0.122931 -0.108840  0.100418   \n",
      "7 -0.019660 -0.026724 -0.019054 -0.090082 -0.017617  0.043999 -0.161656   \n",
      "8 -0.160007  0.068005  0.042184  0.157873 -0.054934 -0.061805  0.099774   \n",
      "9 -0.067242 -0.037838  0.031479 -0.158425 -0.153505  0.276874 -0.232607   \n",
      "\n",
      "         7         8         9   ...        43        44        45        46  \\\n",
      "0  0.095057  0.109287  0.058001  ...  0.134977  0.086334  0.294137  0.108259   \n",
      "1 -0.091537 -0.049972 -0.036550  ... -0.114545 -0.022581  0.288710 -0.116903   \n",
      "2  0.098514 -0.021648  0.068149  ...  0.281094  0.023797 -0.048673  0.093211   \n",
      "3  0.038810  0.029874 -0.050220  ... -0.013497 -0.003373  0.224769 -0.016472   \n",
      "4 -0.419909 -0.018783 -0.240093  ...  0.265447 -0.140975  0.102024 -0.088459   \n",
      "5 -0.360765  0.002540  0.349467  ... -0.035265  0.232938 -0.010935 -0.046001   \n",
      "6 -0.171444  0.054646 -0.107038  ... -0.153090  0.083291 -0.084602 -0.138241   \n",
      "7 -0.230229 -0.116350 -0.027764  ... -0.030214  0.099464 -0.066122  0.016635   \n",
      "8  0.025855 -0.067028 -0.089496  ...  0.075542  0.241056 -0.091074 -0.049614   \n",
      "9 -0.056294  0.125732  0.300700  ...  0.127706 -0.006752 -0.004795 -0.092328   \n",
      "\n",
      "         47        48        49        50        51        52  \n",
      "0  0.051475  0.166643  0.089444  0.092192  0.247697  0.099421  \n",
      "1 -0.076319 -0.228313 -0.078315 -0.134721  0.206759 -0.156031  \n",
      "2  0.050170 -0.250084  0.048405  0.134136 -0.031093  0.398268  \n",
      "3 -0.031381 -0.001309  0.026431  0.031464 -0.321178 -0.063464  \n",
      "4 -0.051504  0.014046 -0.307573  0.000344  0.052430  0.344655  \n",
      "5  0.184128 -0.144904 -0.308266  0.018961 -0.094513 -0.067216  \n",
      "6  0.121184  0.207606 -0.058217 -0.094552 -0.029111 -0.141483  \n",
      "7 -0.148788  0.133934 -0.116002  0.404331 -0.079599 -0.036522  \n",
      "8 -0.122126 -0.123335  0.017918 -0.212177 -0.257694  0.132609  \n",
      "9 -0.118248  0.320696 -0.002917 -0.269654  0.060051  0.098034  \n",
      "\n",
      "[10 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "print(lsa_model.components_.shape) # (no_of_topics*no_of_words)\n",
    "print(pd.DataFrame(lsa_model.components_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a0118",
   "metadata": {},
   "source": [
    "<h3>Hasil TruncatedSVD</h3>\n",
    "\n",
    "berikut adalah contoh 10 kata penting ditiap topik yang diproses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe7bba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "anak akurasi 89 angka 93 95 aliran 83 55 aksesoris \n",
      "\n",
      "Topic 1: \n",
      "anak 95 aliran angka akurasi 83 alphabet 89 93 akademik \n",
      "\n",
      "Topic 2: \n",
      "aplikasi alert alternatif 79 angin 64 ak algoritma 82 akurat \n",
      "\n",
      "Topic 3: \n",
      "93 89 akurasi anak 95 akurat 94 acuan 30 ak \n",
      "\n",
      "Topic 4: \n",
      "aplikasi alert alternatif alphanumerik 85 anak 71 95 akurasi alat \n",
      "\n",
      "Topic 5: \n",
      "84 49 algoritma ambang admin 23 adaptive analisis 64 85 \n",
      "\n",
      "Topic 6: \n",
      "82 64 aksesoris 10 analysis 94 aktor 55 15 2013 \n",
      "\n",
      "Topic 7: \n",
      "angin akurat ak aksesoris akademik 94 admin 88 analysis 83 \n",
      "\n",
      "Topic 8: \n",
      "akademik 88 ambang 83 89 alert admin 2011 aplikasi 2dpca \n",
      "\n",
      "Topic 9: \n",
      "analysis 49 23 aksesoris 84 alert alternatif 47 acuan aplikasi \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vect.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feae4e9",
   "metadata": {},
   "source": [
    "<p>List di atas adalah list kata tiap topik yang sering keluar disetiap dokumen</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6479f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda_model=LatentDirichletAllocation(n_components=10,learning_method='online',random_state=42,max_iter=1) \n",
    "# n_components is the number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "162b0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_top=lda_model.fit_transform(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0eb9bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n",
      "            0         1         2         3         4         5         6  \\\n",
      "0    0.087092  0.087167  0.134061  0.087059  0.087052  0.087050  0.169293   \n",
      "1    0.077326  0.077294  0.077294  0.077294  0.077293  0.077296  0.077300   \n",
      "2    0.076829  0.075987  0.314588  0.075982  0.075976  0.076000  0.076011   \n",
      "3    0.085576  0.138646  0.085527  0.085524  0.085527  0.085506  0.085554   \n",
      "4    0.076603  0.076601  0.076600  0.076601  0.076608  0.310569  0.076601   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "995  0.085299  0.085295  0.085299  0.085290  0.085288  0.085289  0.085286   \n",
      "996  0.093216  0.092859  0.092838  0.092836  0.092871  0.092857  0.092877   \n",
      "997  0.082317  0.082324  0.082314  0.082313  0.082319  0.082310  0.259161   \n",
      "998  0.093930  0.094265  0.093983  0.153448  0.094120  0.093969  0.093936   \n",
      "999  0.083687  0.083628  0.083629  0.083627  0.083625  0.083633  0.083640   \n",
      "\n",
      "            7         8         9  \n",
      "0    0.087128  0.087064  0.087035  \n",
      "1    0.077294  0.077295  0.304314  \n",
      "2    0.076010  0.076224  0.076393  \n",
      "3    0.085504  0.177097  0.085540  \n",
      "4    0.076599  0.076608  0.076611  \n",
      "..        ...       ...       ...  \n",
      "995  0.232373  0.085293  0.085288  \n",
      "996  0.163964  0.092836  0.092846  \n",
      "997  0.082310  0.082322  0.082309  \n",
      "998  0.094056  0.094312  0.093980  \n",
      "999  0.083627  0.083631  0.247273  \n",
      "\n",
      "[1000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(lda_top.shape)  # (no_of_doc,no_of_topics)\n",
    "print(pd.DataFrame(lda_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84e59ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "sum=0\n",
    "for i in lda_top[0]:\n",
    "  sum=sum+i\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64e8423a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: \n",
      "Topic  0 :  8.709153481708022 %\n",
      "Topic  1 :  8.716695034312814 %\n",
      "Topic  2 :  13.406128303393967 %\n",
      "Topic  3 :  8.705874168247345 %\n",
      "Topic  4 :  8.70523288192736 %\n",
      "Topic  5 :  8.704966483060026 %\n",
      "Topic  6 :  16.929272220568716 %\n",
      "Topic  7 :  8.71277056908348 %\n",
      "Topic  8 :  8.70644228424931 %\n",
      "Topic  9 :  8.703464573448978 %\n"
     ]
    }
   ],
   "source": [
    "# composition of doc 0 for eg\n",
    "print(\"Document 0: \")\n",
    "for i,topic in enumerate(lda_top[0]):\n",
    "  print(\"Topic \",i,\": \",topic*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd92c9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0  2.400921  0.438430  0.402438  0.396266  0.750646  0.413491  0.349262   \n",
      "1  0.380390  0.333192  0.400007  0.354619  3.116947  0.338409  0.391648   \n",
      "2  0.413179  3.504743  4.265508  0.419454  0.513505  0.714777  0.444852   \n",
      "3  0.380846  0.712788  0.341327  3.133547  0.422094  0.352413  3.317880   \n",
      "4  0.685820  0.607540  0.502858  0.429167  0.456768  0.421257  0.581143   \n",
      "5  0.414249  0.317296  0.316882  0.483242  0.309278  2.286915  0.442019   \n",
      "6  0.349023  0.369598  0.354725  0.330858  0.563234  0.346109  0.507389   \n",
      "7  0.342231  0.338335  0.372045  0.392474  0.294119  0.267297  0.526056   \n",
      "8  0.520493  0.306261  0.477029  0.420385  0.403138  0.551377  0.386706   \n",
      "9  0.592538  0.496734  0.411082  0.419531  0.552470  0.403008  0.370583   \n",
      "\n",
      "         7         8         9   ...        43        44        45        46  \\\n",
      "0  2.186223  0.671951  0.427236  ...  0.471393  0.485204  3.050398  0.731387   \n",
      "1  0.295904  0.319870  0.353511  ...  2.402193  0.343251  0.395258  0.351237   \n",
      "2  0.436249  0.387606  0.379121  ...  0.634024  0.632650  0.429148  3.215887   \n",
      "3  0.487366  0.563227  0.869583  ...  0.487732  0.478017  0.367969  0.661670   \n",
      "4  0.867152  2.838171  0.553291  ...  0.796743  0.469516  0.383539  0.333045   \n",
      "5  0.498231  0.397935  0.353325  ...  0.428655  0.514783  0.290851  0.383028   \n",
      "6  1.007049  0.693227  0.374035  ...  0.478640  0.404235  0.343486  0.305857   \n",
      "7  0.532491  0.880609  0.361147  ...  0.421128  0.441575  0.643613  0.421536   \n",
      "8  0.299037  0.344021  2.783579  ...  0.390440  2.856667  0.361484  0.678717   \n",
      "9  0.356675  0.531763  0.383839  ...  0.999001  0.386033  0.504849  0.528367   \n",
      "\n",
      "         47        48        49        50        51        52  \n",
      "0  0.354123  2.850566  0.624126  0.414404  0.729209  0.454188  \n",
      "1  0.712146  0.405295  0.618528  0.430981  0.365460  0.539490  \n",
      "2  0.474123  0.578778  0.533027  0.449611  0.550962  0.417820  \n",
      "3  1.982982  0.508669  0.482709  0.326630  0.494186  0.346507  \n",
      "4  0.714888  0.281027  0.662797  0.582476  0.425783  0.622400  \n",
      "5  0.371119  0.317675  0.319342  0.452758  0.486677  0.372080  \n",
      "6  0.328332  0.349977  2.635343  0.326782  0.420092  0.305525  \n",
      "7  0.603151  0.594814  0.404821  0.555702  2.896580  0.396560  \n",
      "8  0.819469  0.368623  0.638237  0.337650  0.455646  0.361518  \n",
      "9  0.440120  0.434511  0.354234  4.006118  0.392179  2.351652  \n",
      "\n",
      "[10 rows x 53 columns]\n",
      "(10, 53)\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(lda_model.components_))\n",
    "print(lda_model.components_.shape)  # (no_of_topics*no_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef85dd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "anak analysis akurasi 00 admin aksesoris 30 93 89 95 \n",
      "\n",
      "Topic 1: \n",
      "2013 akademik alternatif 55 83 analisis 89 android 85 aplikasi \n",
      "\n",
      "Topic 2: \n",
      "15 10 analisa 94 adaptive 82 alat 84 53 algoritma \n",
      "\n",
      "Topic 3: \n",
      "2dpca 2011 96 alat 98 acuan analisis aksesoris 49 10 \n",
      "\n",
      "Topic 4: \n",
      "79 akurat aktor 47 88 53 algoritma 30 ak 73 \n",
      "\n",
      "Topic 5: \n",
      "73 ak 23 admin ambang 30 angka 2011 aksesoris 53 \n",
      "\n",
      "Topic 6: \n",
      "android 83 64 89 30 aliran 82 47 93 2013 \n",
      "\n",
      "Topic 7: \n",
      "alphabet alphanumerik angka 85 55 aliran 95 alat 83 84 \n",
      "\n",
      "Topic 8: \n",
      "ambang 71 49 84 algoritma admin analisis ak analisa android \n",
      "\n",
      "Topic 9: \n",
      "angin aktivitas alert 93 aplikasi alternatif akurat ak 64 algoritma \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vect.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046d73b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
